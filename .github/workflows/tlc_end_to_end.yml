name: NYC TLC End-to-End (Parquet → CSV → SQL)

on:
  workflow_dispatch:
    inputs:
      start_year:
        description: "Start year (e.g. 2022)"
        required: true
        default: "2022"

      start_month:
        description: "Start month (1–12)"
        required: true
        default: "10"

      end_year:
        description: "End year (e.g. 2025)"
        required: true
        default: "2025"

      end_month:
        description: "End month (1–12)"
        required: true
        default: "10"

      force_reprocess:
        description: "Force full reprocess (ignore logs, rebuild CSVs)? yes/no"
        required: true
        default: "no"

      confirm_force:
        description: "Type YES to confirm force reprocess (required if force_reprocess=yes)"
        required: false
        default: ""

      delete_existing_csv:
        description: "Delete existing CSV blobs before rebuild? yes/no"
        required: true
        default: "no"

  schedule:
    # Monthly auto-run: 02:15 UTC on day 2 of month
    - cron: "15 2 2 * *"

jobs:
  run-pipeline:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      # Required for pyodbc → Azure SQL
      - name: Install Microsoft ODBC Driver 18
        run: |
          sudo apt-get update
          sudo apt-get install -y curl apt-transport-https gnupg
          curl https://packages.microsoft.com/keys/microsoft.asc | sudo apt-key add -
          curl https://packages.microsoft.com/config/ubuntu/22.04/prod.list | sudo tee /etc/apt/sources.list.d/mssql-release.list
          sudo apt-get update
          sudo ACCEPT_EULA=Y apt-get install -y msodbcsql18 unixodbc-dev

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Debug – list scripts directory
        run: |
          ls -la scripts

      # =========================================================
      # PHASE 1 — Download Parquet → Azure Blob
      # =========================================================
      - name: Phase 1 – Download Parquet and Upload to Blob
        env:
          STORAGE_ACCOUNT_URL: ${{ secrets.STORAGE_ACCOUNT_URL }}
          STORAGE_CONTAINER: ${{ secrets.STORAGE_CONTAINER }}
          STORAGE_ACCOUNT_KEY: ${{ secrets.STORAGE_ACCOUNT_KEY }}

          START_YEAR: ${{ github.event.inputs.start_year }}
          START_MONTH: ${{ github.event.inputs.start_month }}
          END_YEAR: ${{ github.event.inputs.end_year }}
          END_MONTH: ${{ github.event.inputs.end_month }}

          # Safe default: never delete Parquet automatically
          DELETE_EXISTING: "no"
        run: |
          python scripts/download_yellow_parquet.py

      # =========================================================
      # SAFETY GATE — "Prompt-like" confirmation for destructive run
      # =========================================================
      - name: Safety gate – confirm FORCE_REPROCESS
        run: |
          echo "force_reprocess=${{ github.event.inputs.force_reprocess }}"
          echo "confirm_force=${{ github.event.inputs.confirm_force }}"
          if [ "${{ github.event.inputs.force_reprocess }}" = "yes" ] && [ "${{ github.event.inputs.confirm_force }}" != "YES" ]; then
            echo "ERROR: You set force_reprocess=yes but did not type confirm_force=YES"
            exit 1
          fi

      # =========================================================
      # PHASE 2 — Parquet → CSV → BULK INSERT → FACT
      # =========================================================
      - name: Phase 2 – Convert Parquet → CSV → Load Azure SQL
        env:
          STORAGE_ACCOUNT_URL: ${{ secrets.STORAGE_ACCOUNT_URL }}
          STORAGE_CONTAINER: ${{ secrets.STORAGE_CONTAINER }}
          STORAGE_ACCOUNT_KEY: ${{ secrets.STORAGE_ACCOUNT_KEY }}

          SQL_SERVER: ${{ secrets.SQL_SERVER }}
          SQL_DATABASE: ${{ secrets.SQL_DATABASE }}
          SQL_USERNAME: ${{ secrets.SQL_USERNAME }}
          SQL_PASSWORD: ${{ secrets.SQL_PASSWORD }}

          START_YEAR: ${{ github.event.inputs.start_year }}
          START_MONTH: ${{ github.event.inputs.start_month }}
          END_YEAR: ${{ github.event.inputs.end_year }}
          END_MONTH: ${{ github.event.inputs.end_month }}

          # Control flags
          FORCE_REPROCESS: ${{ github.event.inputs.force_reprocess }}
          DELETE_EXISTING_CSV: ${{ github.event.inputs.delete_existing_csv }}
        run: |
          python scripts/parquet_to_csv_and_load_sql.py
